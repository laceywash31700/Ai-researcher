{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2706c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import fetch_from_arxiv\n",
    "\n",
    "papers = fetch_from_arxiv(\"Language Models\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b319ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cat, Rat, Meow: On the Alignment of Language Model and Human Term-Similarity Judgments',\n",
       " 'C3PO: Critical-Layer, Core-Expert, Collaborative Pathway Optimization for Test-Time Expert Re-Mixing',\n",
       " 'GLUS: Global-Local Reasoning Unified into A Single Large Language Model for Video Segmentation',\n",
       " 'MM-IFEngine: Towards Multimodal Instruction Following',\n",
       " 'VCR-Bench: A Comprehensive Evaluation Framework for Video Chain-of-Thought Reasoning',\n",
       " 'Dynamic Cheatsheet: Test-Time Learning with Adaptive Memory',\n",
       " 'Echo Chamber: RL Post-training Amplifies Behaviors Learned in Pretraining',\n",
       " 'Porting an LLM based Application from ChatGPT to an On-Premise Environment',\n",
       " 'Redefining Machine Translation on Social Network Services with Large Language Models',\n",
       " 'How do Large Language Models Understand Relevance? A Mechanistic Interpretability Perspective']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[paper['title'] for paper in papers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8b0edab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "def create_documents_paper(papers):\n",
    "    documents = []\n",
    "    for paper in papers:\n",
    "        content = (\n",
    "            f\"Tilte: {paper['title']}\\n\"\n",
    "            f\"Authors: {', '.join(paper['authors'])}\\n\"\n",
    "            f\"Summary: {paper['summary']}\\n\"\n",
    "            f\"Published: {paper['published']}\\n\"\n",
    "            f\"Journal Reference: {paper['journal_ref']}\\n\"\n",
    "            f\"DOI: {paper['doi']}\\n\"\n",
    "            f\"Primary Category: {paper['primary_category']}\\n\"\n",
    "            f\"Categories: {', '.join(paper['categories'])}\\n\"\n",
    "            f\"PDF URL: {paper['pdf_url']}\\n\"\n",
    "            f\"arXiv URL: {paper['arxiv_url']}\\n\"\n",
    "            )\n",
    "        documents.append(Document(text=content))\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9791e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = create_documents_paper(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc0ca816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='edf64b8a-c9fb-47a5-a635-e391bd53bbdc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Tilte: Cat, Rat, Meow: On the Alignment of Language Model and Human Term-Similarity Judgments\\nAuthors: Lorenz Linhardt, Tom Neuhäuser, Lenka Tětková, Oliver Eberle\\nSummary: Small and mid-sized generative language models have gained increasing\\nattention. Their size and availability make them amenable to being analyzed at\\na behavioral as well as a representational level, allowing investigations of\\nhow these levels interact. We evaluate 32 publicly available language models\\nfor their representational and behavioral alignment with human similarity\\njudgments on a word triplet task. This provides a novel evaluation setting to\\nprobe semantic associations in language beyond common pairwise comparisons. We\\nfind that (1) even the representations of small language models can achieve\\nhuman-level alignment, (2) instruction-tuned model variants can exhibit\\nsubstantially increased agreement, (3) the pattern of alignment across layers\\nis highly model dependent, and (4) alignment based on models' behavioral\\nresponses is highly dependent on model size, matching their representational\\nalignment only for the largest evaluated models.\\nPublished: 2025-04-10 17:59:57+00:00\\nJournal Reference: None\\nDOI: None\\nPrimary Category: cs.LG\\nCategories: cs.LG, cs.CL\\nPDF URL: http://arxiv.org/pdf/2504.07965v1\\narXiv URL: http://arxiv.org/abs/2504.07965v1\\n\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='662bf948-3fc6-4652-a8b0-1e8e89ac0f02', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Tilte: C3PO: Critical-Layer, Core-Expert, Collaborative Pathway Optimization for Test-Time Expert Re-Mixing\\nAuthors: Zhongyang Li, Ziyue Li, Tianyi Zhou\\nSummary: Mixture-of-Experts (MoE) Large Language Models (LLMs) suffer from severely\\nsub-optimal expert pathways-our study reveals that naive expert selection\\nlearned from pretraining leaves a surprising 10-20% accuracy gap for\\nimprovement. Motivated by this observation, we develop a novel class of\\ntest-time optimization methods to re-weight or \"re-mixing\" the experts in\\ndifferent layers jointly for each test sample. Since the test sample\\'s ground\\ntruth is unknown, we propose to optimize a surrogate objective defined by the\\nsample\\'s \"successful neighbors\" from a reference set of samples. We introduce\\nthree surrogates and algorithms based on mode-finding, kernel regression, and\\nthe average loss of similar reference samples/tasks. To reduce the cost of\\noptimizing whole pathways, we apply our algorithms merely to the core experts\\'\\nmixing weights in critical layers, which enjoy similar performance but save\\nsignificant computation. This leads to \"Critical-Layer, Core-Expert,\\nCollaborative Pathway Optimization (C3PO)\". We apply C3PO to two recent MoE\\nLLMs and examine it on six widely-used benchmarks. It consistently improves the\\nbase model by 7-15% in accuracy and outperforms widely used test-time learning\\nbaselines, e.g., in-context learning and prompt/prefix tuning, by a large\\nmargin. Moreover, C3PO enables MoE LLMs with 1-3B active parameters to\\noutperform LLMs of 7-9B parameters, hence improving MoE\\'s advantages on\\nefficiency. Our thorough ablation study further sheds novel insights on\\nachieving test-time improvement on MoE.\\nPublished: 2025-04-10 17:59:56+00:00\\nJournal Reference: None\\nDOI: None\\nPrimary Category: cs.LG\\nCategories: cs.LG\\nPDF URL: http://arxiv.org/pdf/2504.07964v1\\narXiv URL: http://arxiv.org/abs/2504.07964v1\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='c1827287-998e-4848-871e-da4f270c91f5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Tilte: GLUS: Global-Local Reasoning Unified into A Single Large Language Model for Video Segmentation\\nAuthors: Lang Lin, Xueyang Yu, Ziqi Pang, Yu-Xiong Wang\\nSummary: This paper proposes a novel framework utilizing multi-modal large language\\nmodels (MLLMs) for referring video object segmentation (RefVOS). Previous\\nMLLM-based methods commonly struggle with the dilemma between \"Ref\" and \"VOS\":\\nthey either specialize in understanding a few key frames (global reasoning) or\\ntracking objects on continuous frames (local reasoning), and rely on external\\nVOS or frame selectors to mitigate the other end of the challenge. However, our\\nframework GLUS shows that global and local consistency can be unified into a\\nsingle video segmentation MLLM: a set of sparse \"context frames\" provides\\nglobal information, while a stream of continuous \"query frames\" conducts local\\nobject tracking. This is further supported by jointly training the MLLM with a\\npre-trained VOS memory bank to simultaneously digest short-range and long-range\\ntemporal information. To improve the information efficiency within the limited\\ncontext window of MLLMs, we introduce object contrastive learning to\\ndistinguish hard false-positive objects and a self-refined framework to\\nidentify crucial frames and perform propagation. By collectively integrating\\nthese insights, our GLUS delivers a simple yet effective baseline, achieving\\nnew state-of-the-art for MLLMs on the MeViS and Ref-Youtube-VOS benchmark. Our\\nproject page is at https://glus-video.github.io/.\\nPublished: 2025-04-10 17:59:55+00:00\\nJournal Reference: None\\nDOI: None\\nPrimary Category: cs.CV\\nCategories: cs.CV\\nPDF URL: http://arxiv.org/pdf/2504.07962v1\\narXiv URL: http://arxiv.org/abs/2504.07962v1\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='94ce4e87-ca27-4c5c-9262-f1c3f7a4b192', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Tilte: MM-IFEngine: Towards Multimodal Instruction Following\\nAuthors: Shengyuan Ding, Shenxi Wu, Xiangyu Zhao, Yuhang Zang, Haodong Duan, Xiaoyi Dong, Pan Zhang, Yuhang Cao, Dahua Lin, Jiaqi Wang\\nSummary: The Instruction Following (IF) ability measures how well Multi-modal Large\\nLanguage Models (MLLMs) understand exactly what users are telling them and\\nwhether they are doing it right. Existing multimodal instruction following\\ntraining data is scarce, the benchmarks are simple with atomic instructions,\\nand the evaluation strategies are imprecise for tasks demanding exact output\\nconstraints. To address this, we present MM-IFEngine, an effective pipeline to\\ngenerate high-quality image-instruction pairs. Our MM-IFEngine pipeline yields\\nlarge-scale, diverse, and high-quality training data MM-IFInstruct-23k, which\\nis suitable for Supervised Fine-Tuning (SFT) and extended as MM-IFDPO-23k for\\nDirect Preference Optimization (DPO). We further introduce MM-IFEval, a\\nchallenging and diverse multi-modal instruction-following benchmark that\\nincludes (1) both compose-level constraints for output responses and\\nperception-level constraints tied to the input images, and (2) a comprehensive\\nevaluation pipeline incorporating both rule-based assessment and judge model.\\nWe conduct SFT and DPO experiments and demonstrate that fine-tuning MLLMs on\\nMM-IFInstruct-23k and MM-IFDPO-23k achieves notable gains on various IF\\nbenchmarks, such as MM-IFEval (+10.2$\\\\%$), MIA (+7.6$\\\\%$), and IFEval\\n(+12.3$\\\\%$). The full data and evaluation code will be released on\\nhttps://github.com/SYuan03/MM-IFEngine.\\nPublished: 2025-04-10 17:59:12+00:00\\nJournal Reference: None\\nDOI: None\\nPrimary Category: cs.CV\\nCategories: cs.CV\\nPDF URL: http://arxiv.org/pdf/2504.07957v1\\narXiv URL: http://arxiv.org/abs/2504.07957v1\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='4c895295-a2c6-4abc-95f1-588b2734ea81', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Tilte: VCR-Bench: A Comprehensive Evaluation Framework for Video Chain-of-Thought Reasoning\\nAuthors: Yukun Qi, Yiming Zhao, Yu Zeng, Xikun Bao, Wenxuan Huang, Lin Chen, Zehui Chen, Jie Zhao, Zhongang Qi, Feng Zhao\\nSummary: The advancement of Chain-of-Thought (CoT) reasoning has significantly\\nenhanced the capabilities of large language models (LLMs) and large\\nvision-language models (LVLMs). However, a rigorous evaluation framework for\\nvideo CoT reasoning remains absent. Current video benchmarks fail to adequately\\nassess the reasoning process and expose whether failures stem from deficiencies\\nin perception or reasoning capabilities. Therefore, we introduce VCR-Bench, a\\nnovel benchmark designed to comprehensively evaluate LVLMs' Video\\nChain-of-Thought Reasoning capabilities. VCR-Bench comprises 859 videos\\nspanning a variety of video content and durations, along with 1,034\\nhigh-quality question-answer pairs. Each pair is manually annotated with a\\nstepwise CoT rationale, where every step is tagged to indicate its association\\nwith the perception or reasoning capabilities. Furthermore, we design seven\\ndistinct task dimensions and propose the CoT score to assess the entire CoT\\nprocess based on the stepwise tagged CoT rationals. Extensive experiments on\\nVCR-Bench highlight substantial limitations in current LVLMs. Even the\\ntop-performing model, o1, only achieves a 62.8% CoT score and an 56.7%\\naccuracy, while most models score below 40%. Experiments show most models score\\nlower on perception than reasoning steps, revealing LVLMs' key bottleneck in\\ntemporal-spatial information processing for complex video reasoning. A robust\\npositive correlation between the CoT score and accuracy confirms the validity\\nof our evaluation framework and underscores the critical role of CoT reasoning\\nin solving complex video reasoning tasks. We hope VCR-Bench to serve as a\\nstandardized evaluation framework and expose the actual drawbacks in complex\\nvideo reasoning task.\\nPublished: 2025-04-10 17:59:03+00:00\\nJournal Reference: None\\nDOI: None\\nPrimary Category: cs.CV\\nCategories: cs.CV, cs.AI, cs.CL\\nPDF URL: http://arxiv.org/pdf/2504.07956v1\\narXiv URL: http://arxiv.org/abs/2504.07956v1\\n\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='a0c66e92-4627-441b-8184-ad229f58f7aa', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Tilte: Dynamic Cheatsheet: Test-Time Learning with Adaptive Memory\\nAuthors: Mirac Suzgun, Mert Yuksekgonul, Federico Bianchi, Dan Jurafsky, James Zou\\nSummary: Despite their impressive performance on complex tasks, current language\\nmodels (LMs) typically operate in a vacuum: Each input query is processed\\nseparately, without retaining insights from previous attempts. Here, we present\\nDynamic Cheatsheet (DC), a lightweight framework that endows a black-box LM\\nwith a persistent, evolving memory. Rather than repeatedly re-discovering or\\nre-committing the same solutions and mistakes, DC enables models to store and\\nreuse accumulated strategies, code snippets, and general problem-solving\\ninsights at inference time. This test-time learning enhances performance\\nsubstantially across a range of tasks without needing explicit ground-truth\\nlabels or human feedback. Leveraging DC, Claude 3.5 Sonnet's accuracy more than\\ndoubled on AIME math exams once it began retaining algebraic insights across\\nquestions. Similarly, GPT-4o's success rate on Game of 24 increased from 10% to\\n99% after the model discovered and reused a Python-based solution. In tasks\\nprone to arithmetic mistakes, such as balancing equations, DC enabled GPT-4o\\nand Claude to reach near-perfect accuracy by recalling previously validated\\ncode, whereas their baselines stagnated around 50%. Beyond arithmetic\\nchallenges, DC yields notable accuracy gains on knowledge-demanding tasks.\\nClaude achieved a 9% improvement in GPQA-Diamond and an 8% boost on MMLU-Pro\\nproblems. Crucially, DC's memory is self-curated, focusing on concise,\\ntransferable snippets rather than entire transcript. Unlike finetuning or\\nstatic retrieval methods, DC adapts LMs' problem-solving skills on the fly,\\nwithout modifying their underlying parameters. Overall, our findings present DC\\nas a promising approach for augmenting LMs with persistent memory, bridging the\\ndivide between isolated inference events and the cumulative, experience-driven\\nlearning characteristic of human cognition.\\nPublished: 2025-04-10 17:57:33+00:00\\nJournal Reference: None\\nDOI: None\\nPrimary Category: cs.LG\\nCategories: cs.LG, cs.CL\\nPDF URL: http://arxiv.org/pdf/2504.07952v1\\narXiv URL: http://arxiv.org/abs/2504.07952v1\\n\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='52d380d7-c9e6-4f1c-b5a2-a4d7d264a647', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Tilte: Echo Chamber: RL Post-training Amplifies Behaviors Learned in Pretraining\\nAuthors: Rosie Zhao, Alexandru Meterez, Sham Kakade, Cengiz Pehlevan, Samy Jelassi, Eran Malach\\nSummary: Reinforcement learning (RL)-based fine-tuning has become a crucial step in\\npost-training language models for advanced mathematical reasoning and coding.\\nFollowing the success of frontier reasoning models, recent work has\\ndemonstrated that RL fine-tuning consistently improves performance, even in\\nsmaller-scale models; however, the underlying mechanisms driving these\\nimprovements are not well-understood. Understanding the effects of RL\\nfine-tuning requires disentangling its interaction with pretraining data\\ncomposition, hyperparameters, and model scale, but such problems are\\nexacerbated by the lack of transparency regarding the training data used in\\nmany existing models. In this work, we present a systematic end-to-end study of\\nRL fine-tuning for mathematical reasoning by training models entirely from\\nscratch on different mixtures of fully open datasets. We investigate the\\neffects of various RL fine-tuning algorithms (PPO, GRPO, and Expert Iteration)\\nacross models of different scales. Our study reveals that RL algorithms\\nconsistently converge towards a dominant output distribution, amplifying\\npatterns in the pretraining data. We also find that models of different scales\\ntrained on the same data mixture will converge to distinct output\\ndistributions, suggesting that there are scale-dependent biases in model\\ngeneralization. Moreover, we find that RL post-training on simpler questions\\ncan lead to performance gains on harder ones, indicating that certain reasoning\\ncapabilities generalize across tasks. Our findings show that small-scale\\nproxies in controlled settings can elicit interesting insights regarding the\\nrole of RL in shaping language model behavior.\\nPublished: 2025-04-10 17:15:53+00:00\\nJournal Reference: None\\nDOI: None\\nPrimary Category: cs.LG\\nCategories: cs.LG, I.2.7\\nPDF URL: http://arxiv.org/pdf/2504.07912v1\\narXiv URL: http://arxiv.org/abs/2504.07912v1\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='d589420b-8bae-464d-acc2-ac242a880876', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Tilte: Porting an LLM based Application from ChatGPT to an On-Premise Environment\\nAuthors: Teemu Paloniemi, Manu Setälä, Tommi Mikkonen\\nSummary: Given the data-intensive nature of Machine Learning (ML) systems in general,\\nand Large Language Models (LLM) in particular, using them in cloud based\\nenvironments can become a challenge due to legislation related to privacy and\\nsecurity of data. Taking such aspects into consideration implies porting the\\nLLMs to an on-premise environment, where privacy and security can be\\ncontrolled. In this paper, we study this porting process of a real-life\\napplication using ChatGPT, which runs in a public cloud, to an on-premise\\nenvironment. The application being ported is AIPA, a system that leverages\\nLarge Language Models (LLMs) and sophisticated data analytics to enhance the\\nassessment of procurement call bids. The main considerations in the porting\\nprocess include transparency of open source models and cost of hardware, which\\nare central design choices of the on-premise environment. In addition to\\npresenting the porting process, we evaluate downsides and benefits associated\\nwith porting.\\nPublished: 2025-04-10 16:29:26+00:00\\nJournal Reference: None\\nDOI: None\\nPrimary Category: cs.SE\\nCategories: cs.SE\\nPDF URL: http://arxiv.org/pdf/2504.07907v1\\narXiv URL: http://arxiv.org/abs/2504.07907v1\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='47aeb85d-d18a-41f9-9d7a-aa2e4b993cd6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Tilte: Redefining Machine Translation on Social Network Services with Large Language Models\\nAuthors: Hongcheng Guo, Fei Zhao, Shaosheng Cao, Xinze Lyu, Ziyan Liu, Yue Wang, Boyang Wang, Zhoujun Li, Chonggang Lu, Zhe Xu, Yao Hu\\nSummary: The globalization of social interactions has heightened the need for machine\\ntranslation (MT) on Social Network Services (SNS), yet traditional models\\nstruggle with culturally nuanced content like memes, slang, and pop culture\\nreferences. While large language models (LLMs) have advanced general-purpose\\ntranslation, their performance on SNS-specific content remains limited due to\\ninsufficient specialized training data and evaluation benchmarks. This paper\\nintroduces RedTrans, a 72B LLM tailored for SNS translation, trained on a novel\\ndataset developed through three innovations: (1) Supervised Finetuning with\\nDual-LLM Back-Translation Sampling, an unsupervised sampling method using\\nLLM-based back-translation to select diverse data for large-scale finetuning;\\n(2) Rewritten Preference Optimization (RePO), an algorithm that identifies and\\ncorrects erroneous preference pairs through expert annotation, building\\nreliable preference corpora; and (3) RedTrans-Bench, the first benchmark for\\nSNS translation, evaluating phenomena like humor localization, emoji semantics,\\nand meme adaptation. Experiments show RedTrans outperforms state-of-the-art\\nLLMs. Besides, RedTrans has already been deployed in a real-world production\\nenvironment, demonstrating that domain-specific adaptation, effectively bridges\\nthe gap between generic and culturally grounded translation systems.\\nPublished: 2025-04-10 16:24:28+00:00\\nJournal Reference: None\\nDOI: None\\nPrimary Category: cs.CL\\nCategories: cs.CL\\nPDF URL: http://arxiv.org/pdf/2504.07901v1\\narXiv URL: http://arxiv.org/abs/2504.07901v1\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='d1ff610b-f0ec-4024-856d-cac39f2ccfbb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Tilte: How do Large Language Models Understand Relevance? A Mechanistic Interpretability Perspective\\nAuthors: Qi Liu, Jiaxin Mao, Ji-Rong Wen\\nSummary: Recent studies have shown that large language models (LLMs) can assess\\nrelevance and support information retrieval (IR) tasks such as document ranking\\nand relevance judgment generation. However, the internal mechanisms by which\\noff-the-shelf LLMs understand and operationalize relevance remain largely\\nunexplored. In this paper, we systematically investigate how different LLM\\nmodules contribute to relevance judgment through the lens of mechanistic\\ninterpretability. Using activation patching techniques, we analyze the roles of\\nvarious model components and identify a multi-stage, progressive process in\\ngenerating either pointwise or pairwise relevance judgment. Specifically, LLMs\\nfirst extract query and document information in the early layers, then process\\nrelevance information according to instructions in the middle layers, and\\nfinally utilize specific attention heads in the later layers to generate\\nrelevance judgments in the required format. Our findings provide insights into\\nthe mechanisms underlying relevance assessment in LLMs, offering valuable\\nimplications for future research on leveraging LLMs for IR tasks.\\nPublished: 2025-04-10 16:14:55+00:00\\nJournal Reference: None\\nDOI: None\\nPrimary Category: cs.IR\\nCategories: cs.IR, cs.CL, cs.LG\\nPDF URL: http://arxiv.org/pdf/2504.07898v1\\narXiv URL: http://arxiv.org/abs/2504.07898v1\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5e48201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings, VectorStoreIndex\n",
    "from constants import embedding_model\n",
    "\n",
    "from constants import embedding_model\n",
    "\n",
    "Settings.chunk_size = 1024\n",
    "Settings.chunk_overlap = 50\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents, embedding_model=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "437e5507",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.storage_context.persist(\"index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
