{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0df98c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from constants import embedding_model\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"index/\")\n",
    "index = load_index_from_storage(storage_context, embedding_model=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203661bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "from constants import llm_model\n",
    "\n",
    "query_engine = index.as_query_engine(llm_model=llm_model, similarity_top_k=5)\n",
    "rag_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine, \n",
    "    name=\"reesarch_paper_query_engine_tool\", \n",
    "    description=\"A RAG engine with recent research papers.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c52c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def display_prompt_dictionary(prompt_dictionary):\n",
    "    for key, prompt in prompt_dictionary.items():\n",
    "        display(Markdown(f\"**Prompt key**:{key}\"))\n",
    "        print(prompt.get_template())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de921f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt key**:response_synthesizer:text_qa_template"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context information is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt key**:response_synthesizer:refine_template"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original query is as follows: {query_str}\n",
      "We have provided an existing answer: {existing_answer}\n",
      "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "------------\n",
      "{context_msg}\n",
      "------------\n",
      "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
      "Refined Answer: \n"
     ]
    }
   ],
   "source": [
    "prompts_dictionary = query_engine.get_prompts()\n",
    "display_prompt_dictionary(prompts_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eba512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import download_pdf, fetch_from_arxiv\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "download_pdf_tool = FunctionTool.from_defaults(\n",
    "    download_pdf, \n",
    "    name=\"download_pdf_file_tool\", \n",
    "    description=\"Python function that downloads PDFs from provided URLs.\"\n",
    "    )\n",
    "\n",
    "fetch_arxiv_tool = FunctionTool.from_defaults(\n",
    "    fetch_from_arxiv, \n",
    "    name=\"fetch_from_arxiv\", \n",
    "    description=\"Download the {max_results} recent papers regarding the topic {title} from arXiv.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57126360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "agent = ReActAgent.from_tools(\n",
    "    [rag_tool, download_pdf_tool, fetch_arxiv_tool], \n",
    "    llm_model=llm_model, \n",
    "    verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f683645",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template = \"\"\"I am intersted in {topic}.\n",
    "Find papers in your knowledge base that discuss this topic.\n",
    "Use the folling template to query research_paper_query_engine_tool tool: \n",
    "'Provide title, summary, author and link to download the PDF for papers related to {topic}'\n",
    "If there are no papers, could you fetch the recent ones from arXiv?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "875caee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step fea4bc67-149c-4f6d-9e04-9c14b2a68206. Step input: I am intersted in Large Language Models.\n",
      "Find papers in your knowledge base that discuss this topic.\n",
      "Use the folling template to query research_paper_query_engine_tool tool: \n",
      "'Provide title, summary, author and link to download the PDF for papers related to Large Language Models'\n",
      "If there are no papers, could you fetch the recent ones from arXiv?\n",
      "\n",
      "\u001b[1;3;38;5;200mThought: The user is interested in finding research papers related to Large Language Models. I can use the research_paper_query_engine_tool to search for papers on this topic. If there are no relevant papers in the knowledge base, I can fetch recent ones from arXiv.\n",
      "Action: reesarch_paper_query_engine_tool\n",
      "Action Input: {'input': 'Provide title, summary, author and link to download the PDF for papers related to Large Language Models'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Title: How do Large Language Models Understand Relevance? A Mechanistic Interpretability Perspective\n",
      "Summary: Recent studies have shown that large language models (LLMs) can assess relevance and support information retrieval (IR) tasks such as document ranking and relevance judgment generation. However, the internal mechanisms by which off-the-shelf LLMs understand and operationalize relevance remain largely unexplored. In this paper, we systematically investigate how different LLM modules contribute to relevance judgment through the lens of mechanistic interpretability. Using activation patching techniques, we analyze the roles of various model components and identify a multi-stage, progressive process in generating either pointwise or pairwise relevance judgment. Specifically, LLMs first extract query and document information in the early layers, then process relevance information according to instructions in the middle layers, and finally utilize specific attention heads in the later layers to generate relevance judgments in the required format.\n",
      "Authors: Qi Liu, Jiaxin Mao, Ji-Rong Wen\n",
      "PDF URL: http://arxiv.org/pdf/2504.07898v1\n",
      "\n",
      "Title: Porting an LLM based Application from ChatGPT to an On-Premise Environment\n",
      "Summary: Given the data-intensive nature of Machine Learning (ML) systems in general, and Large Language Models (LLM) in particular, using them in cloud based environments can become a challenge due to legislation related to privacy and security of data. Taking such aspects into consideration implies porting the LLMs to an on-premise environment, where privacy and security can be controlled. In this paper, we study this porting process of a real-life application using ChatGPT, which runs in a public cloud, to an on-premise environment. The application being ported is AIPA, a system that leverages Large Language Models (LLMs) and sophisticated data analytics to enhance the assessment of procurement call bids. The main considerations in the porting process include transparency of open source models and cost of hardware, which are central design choices of the on-premise environment. In addition to presenting the porting process, we evaluate downsides and benefits associated with porting.\n",
      "Authors: Teemu Paloniemi, Manu Setälä, Tommi Mikkonen\n",
      "PDF URL: http://arxiv.org/pdf/2504.07907v1\n",
      "\n",
      "Title: Redefining Machine Translation on Social Network Services with Large Language Models\n",
      "Summary: The globalization of social interactions has heightened the need for machine translation (MT) on Social Network Services (SNS), yet traditional models struggle with culturally nuanced content like memes, slang, and pop culture references. While large language models (LLMs) have advanced general-purpose translation, their performance on SNS-specific content remains limited due to insufficient specialized training data and evaluation benchmarks. This paper introduces RedTrans, a 72B LLM tailored for SNS translation, trained on a novel dataset developed through three innovations: (1) Supervised Finetuning with Dual-LLM Back-Translation Sampling, an unsupervised sampling method using LLM-based back-translation to select diverse data for large-scale finetuning; (2) Rewritten Preference Optimization (RePO), an algorithm that identifies and corrects erroneous preference pairs through expert annotation, building reliable preference corpora; and (3) RedTrans-Bench, the first benchmark for SNS translation, evaluating phenomena like humor localization, emoji semantics, and meme adaptation. Experiments show RedTrans outperforms state-of-the-art LLMs. Besides, RedTrans has already been deployed in a real-world production environment, demonstrating that domain-specific adaptation effectively bridges the gap between generic and culturally grounded translation systems.\n",
      "Authors: Hongcheng Guo, Fei Zhao, Shaosheng Cao, Xinze Lyu, Ziyan Liu, Yue Wang, Boyang Wang, Zhoujun Li, Chonggang Lu, Zhe Xu, Yao Hu\n",
      "PDF URL: http://arxiv.org/pdf/2504.07901v1\n",
      "\n",
      "Title: Cat, Rat, Meow: On the Alignment of Language Model and Human Term-Similarity Judgments\n",
      "Summary: Small and mid-sized generative language models have gained increasing attention. Their size and availability make them amenable to being analyzed at a behavioral as well as a representational level, allowing investigations of how these levels interact. We evaluate 32 publicly available language models for their representational and behavioral alignment with human similarity judgments on a word triplet task. This provides a novel evaluation setting to probe semantic associations in language beyond common pairwise comparisons. We find that (1) even the representations of small language models can achieve human-level alignment, (2) instruction-tuned model variants can exhibit substantially increased agreement, (3) the pattern of alignment across layers is highly model dependent, and (4) alignment based on models' behavioral responses is highly dependent on model size, matching their representational alignment only for the largest evaluated models.\n",
      "Authors: Lorenz Linhardt, Tom Neuhäuser, Lenka Tětková, Oliver Eberle\n",
      "PDF URL: http://arxiv.org/pdf/2504.07965v1\n",
      "\n",
      "Title: GLUS: Global-Local Reasoning Unified into A Single Large Language Model for Video Segmentation\n",
      "Summary: This paper proposes a novel framework utilizing multi-modal large language models (MLLMs) for referring video object segmentation (RefVOS). Previous MLLM-based methods commonly struggle with the dilemma between \"Ref\" and \"VOS\": they either specialize in understanding a few key frames (global reasoning) or tracking objects on continuous frames (local reasoning), and rely on external VOS or frame selectors to mitigate the other end of the challenge. However, our framework GLUS shows that global and local consistency can be unified into a single video segmentation MLLM: a set of sparse \"context frames\" provides global information, while a stream of continuous \"query frames\" conducts local object tracking. This is further supported by jointly training the MLLM with a pre-trained VOS memory bank to simultaneously digest short-range and long-range temporal information. To improve the information efficiency within the limited context window of MLLMs, we introduce object contrastive learning to distinguish hard false-positive objects and a self-refined framework to identify crucial frames and perform propagation. By collectively integrating these insights, our GLUS delivers a simple yet effective baseline, achieving new state-of-the-art for MLLMs on the MeViS and Ref-Youtube-VOS benchmark. Our project page is at https://glus-video.github.io/.\n",
      "Authors: Lang Lin, Xueyang Yu, Ziqi Pang, Yu-Xiong Wang\n",
      "PDF URL: http://arxiv.org/pdf/2504.07962v1\n",
      "\u001b[0m> Running step a88d12b7-4728-4994-a233-dc59d9b921e9. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The research_paper_query_engine_tool has provided several papers related to Large Language Models, along with their titles, summaries, authors, and PDF URLs.\n",
      "\n",
      "I can now provide the requested information to the user without using any more tools.\n",
      "Answer: 1. Title: How do Large Language Models Understand Relevance? A Mechanistic Interpretability Perspective\n",
      "   Summary: This paper explores how different modules of Large Language Models (LLMs) contribute to relevance judgment through mechanistic interpretability.\n",
      "   Authors: Qi Liu, Jiaxin Mao, Ji-Rong Wen\n",
      "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07898v1)\n",
      "\n",
      "2. Title: Porting an LLM based Application from ChatGPT to an On-Premise Environment\n",
      "   Summary: The paper discusses the process of porting a real-life application using ChatGPT from a public cloud to an on-premise environment.\n",
      "   Authors: Teemu Paloniemi, Manu Setälä, Tommi Mikkonen\n",
      "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07907v1)\n",
      "\n",
      "3. Title: Redefining Machine Translation on Social Network Services with Large Language Models\n",
      "   Summary: This paper introduces RedTrans, a Large Language Model tailored for Social Network Services translation, outperforming state-of-the-art models.\n",
      "   Authors: Hongcheng Guo, Fei Zhao, Shaosheng Cao, Xinze Lyu, Ziyan Liu, Yue Wang, Boyang Wang, Zhoujun Li, Chonggang Lu, Zhe Xu, Yao Hu\n",
      "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07901v1)\n",
      "\n",
      "4. Title: Cat, Rat, Meow: On the Alignment of Language Model and Human Term-Similarity Judgments\n",
      "   Summary: The paper evaluates language models for their alignment with human similarity judgments on a word triplet task.\n",
      "   Authors: Lorenz Linhardt, Tom Neuhäuser, Lenka Tětková, Oliver Eberle\n",
      "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07965v1)\n",
      "\n",
      "5. Title: GLUS: Global-Local Reasoning Unified into A Single Large Language Model for Video Segmentation\n",
      "   Summary: This paper proposes a framework using multi-modal large language models for video object segmentation, achieving state-of-the-art results.\n",
      "   Authors: Lang Lin, Xueyang Yu, Ziqi Pang, Yu-Xiong Wang\n",
      "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07962v1)\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "answer = agent.chat(query_template.format(topic=\"Large Language Models\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d6b3efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. Title: How do Large Language Models Understand Relevance? A Mechanistic Interpretability Perspective\n",
       "   Summary: This paper explores how different modules of Large Language Models (LLMs) contribute to relevance judgment through mechanistic interpretability.\n",
       "   Authors: Qi Liu, Jiaxin Mao, Ji-Rong Wen\n",
       "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07898v1)\n",
       "\n",
       "2. Title: Porting an LLM based Application from ChatGPT to an On-Premise Environment\n",
       "   Summary: The paper discusses the process of porting a real-life application using ChatGPT from a public cloud to an on-premise environment.\n",
       "   Authors: Teemu Paloniemi, Manu Setälä, Tommi Mikkonen\n",
       "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07907v1)\n",
       "\n",
       "3. Title: Redefining Machine Translation on Social Network Services with Large Language Models\n",
       "   Summary: This paper introduces RedTrans, a Large Language Model tailored for Social Network Services translation, outperforming state-of-the-art models.\n",
       "   Authors: Hongcheng Guo, Fei Zhao, Shaosheng Cao, Xinze Lyu, Ziyan Liu, Yue Wang, Boyang Wang, Zhoujun Li, Chonggang Lu, Zhe Xu, Yao Hu\n",
       "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07901v1)\n",
       "\n",
       "4. Title: Cat, Rat, Meow: On the Alignment of Language Model and Human Term-Similarity Judgments\n",
       "   Summary: The paper evaluates language models for their alignment with human similarity judgments on a word triplet task.\n",
       "   Authors: Lorenz Linhardt, Tom Neuhäuser, Lenka Tětková, Oliver Eberle\n",
       "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07965v1)\n",
       "\n",
       "5. Title: GLUS: Global-Local Reasoning Unified into A Single Large Language Model for Video Segmentation\n",
       "   Summary: This paper proposes a framework using multi-modal large language models for video object segmentation, achieving state-of-the-art results.\n",
       "   Authors: Lang Lin, Xueyang Yu, Ziqi Pang, Yu-Xiong Wang\n",
       "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07962v1)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(answer.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d0f6289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 2d6e6277-778a-4601-a1c4-421ac3db1c73. Step input: Downlod all the papers you just metioned.\n",
      "\u001b[1;3;38;5;200mThought: I can download the PDF files of the papers mentioned using the download_pdf_file_tool.\n",
      "Action: download_pdf_file_tool\n",
      "Action Input: {'pdf_url': 'http://arxiv.org/pdf/2504.07898v1', 'output_file_name': 'LLM_Understand_Relevance.pdf'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: PDF saved as 'papers\\LLM_Understand_Relevance.pdf'.\n",
      "\u001b[0m> Running step ed67e6e6-aed4-4042-b060-8f3baabdec25. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can download the PDF files of the remaining papers mentioned using the download_pdf_file_tool.\n",
      "Action: download_pdf_file_tool\n",
      "Action Input: {'pdf_url': 'http://arxiv.org/pdf/2504.07907v1', 'output_file_name': 'LLM_Porting_Application.pdf'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: PDF saved as 'papers\\LLM_Porting_Application.pdf'.\n",
      "\u001b[0m> Running step 9bb14c03-4040-44c4-a5e6-4896f6494766. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can download the PDF files of the remaining papers mentioned using the download_pdf_file_tool.\n",
      "Action: download_pdf_file_tool\n",
      "Action Input: {'pdf_url': 'http://arxiv.org/pdf/2504.07901v1', 'output_file_name': 'LLM_Machine_Translation.pdf'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: PDF saved as 'papers\\LLM_Machine_Translation.pdf'.\n",
      "\u001b[0m> Running step ca694458-734d-42d6-b1a9-9b53cefa32e7. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can download the PDF files of the remaining papers mentioned using the download_pdf_file_tool.\n",
      "Action: download_pdf_file_tool\n",
      "Action Input: {'pdf_url': 'http://arxiv.org/pdf/2504.07965v1', 'output_file_name': 'LLM_Term_Similarity_Judgments.pdf'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: PDF saved as 'papers\\LLM_Term_Similarity_Judgments.pdf'.\n",
      "\u001b[0m> Running step f44f6617-e6e5-4e00-9e49-cbe20b41a21b. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can download the PDF files of the remaining papers mentioned using the download_pdf_file_tool.\n",
      "Action: download_pdf_file_tool\n",
      "Action Input: {'pdf_url': 'http://arxiv.org/pdf/2504.07962v1', 'output_file_name': 'LLM_Video_Segmentation.pdf'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: PDF saved as 'papers\\LLM_Video_Segmentation.pdf'.\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Reached max iterations.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m answer = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDownlod all the papers you just metioned.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\Desktop\\Ai-researcher\\.venv\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:322\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    324\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    325\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\Desktop\\Ai-researcher\\.venv\\Lib\\site-packages\\llama_index\\core\\callbacks\\utils.py:41\u001b[39m, in \u001b[36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m callback_manager = cast(CallbackManager, callback_manager)\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m callback_manager.as_trace(trace_id):\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\Desktop\\Ai-researcher\\.venv\\Lib\\site-packages\\llama_index\\core\\agent\\runner\\base.py:692\u001b[39m, in \u001b[36mAgentRunner.chat\u001b[39m\u001b[34m(self, message, chat_history, tool_choice)\u001b[39m\n\u001b[32m    687\u001b[39m     tool_choice = \u001b[38;5;28mself\u001b[39m.default_tool_choice\n\u001b[32m    688\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    689\u001b[39m     CBEventType.AGENT_STEP,\n\u001b[32m    690\u001b[39m     payload={EventPayload.MESSAGES: [message]},\n\u001b[32m    691\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m692\u001b[39m     chat_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchat_history\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchat_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatResponseMode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWAIT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    698\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chat_response, AgentChatResponse)\n\u001b[32m    699\u001b[39m     e.on_end(payload={EventPayload.RESPONSE: chat_response})\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\Desktop\\Ai-researcher\\.venv\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:322\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    324\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    325\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\Desktop\\Ai-researcher\\.venv\\Lib\\site-packages\\llama_index\\core\\agent\\runner\\base.py:624\u001b[39m, in \u001b[36mAgentRunner._chat\u001b[39m\u001b[34m(self, message, chat_history, tool_choice, mode)\u001b[39m\n\u001b[32m    621\u001b[39m dispatcher.event(AgentChatWithStepStartEvent(user_msg=message))\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    623\u001b[39m     \u001b[38;5;66;03m# pass step queue in as argument, assume step executor is stateless\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m     cur_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_choice\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    628\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cur_step_output.is_last:\n\u001b[32m    629\u001b[39m         result_output = cur_step_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\Desktop\\Ai-researcher\\.venv\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:322\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    324\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    325\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\Desktop\\Ai-researcher\\.venv\\Lib\\site-packages\\llama_index\\core\\agent\\runner\\base.py:420\u001b[39m, in \u001b[36mAgentRunner._run_step\u001b[39m\u001b[34m(self, task_id, step, input, mode, **kwargs)\u001b[39m\n\u001b[32m    416\u001b[39m \u001b[38;5;66;03m# TODO: figure out if you can dynamically swap in different step executors\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[38;5;66;03m# not clear when you would do that by theoretically possible\u001b[39;00m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == ChatResponseMode.WAIT:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     cur_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_worker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == ChatResponseMode.STREAM:\n\u001b[32m    422\u001b[39m     cur_step_output = \u001b[38;5;28mself\u001b[39m.agent_worker.stream_step(step, task, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\Desktop\\Ai-researcher\\.venv\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:322\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    324\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    325\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\Desktop\\Ai-researcher\\.venv\\Lib\\site-packages\\llama_index\\core\\callbacks\\utils.py:41\u001b[39m, in \u001b[36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m callback_manager = cast(CallbackManager, callback_manager)\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m callback_manager.as_trace(trace_id):\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\Desktop\\Ai-researcher\\.venv\\Lib\\site-packages\\llama_index\\core\\agent\\react\\step.py:820\u001b[39m, in \u001b[36mReActAgentWorker.run_step\u001b[39m\u001b[34m(self, step, task, **kwargs)\u001b[39m\n\u001b[32m    817\u001b[39m \u001b[38;5;129m@trace_method\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mrun_step\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, step: TaskStep, task: Task, **kwargs: Any) -> TaskStepOutput:\n\u001b[32m    819\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run step.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\Desktop\\Ai-researcher\\.venv\\Lib\\site-packages\\llama_index\\core\\agent\\react\\step.py:578\u001b[39m, in \u001b[36mReActAgentWorker._run_step\u001b[39m\u001b[34m(self, step, task)\u001b[39m\n\u001b[32m    574\u001b[39m reasoning_steps, is_done = \u001b[38;5;28mself\u001b[39m._process_actions(\n\u001b[32m    575\u001b[39m     task, tools, output=chat_response\n\u001b[32m    576\u001b[39m )\n\u001b[32m    577\u001b[39m task.extra_state[\u001b[33m\"\u001b[39m\u001b[33mcurrent_reasoning\u001b[39m\u001b[33m\"\u001b[39m].extend(reasoning_steps)\n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m agent_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextra_state\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcurrent_reasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextra_state\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msources\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_done:\n\u001b[32m    582\u001b[39m     task.extra_state[\u001b[33m\"\u001b[39m\u001b[33mnew_memory\u001b[39m\u001b[33m\"\u001b[39m].put(\n\u001b[32m    583\u001b[39m         ChatMessage(content=agent_response.response, role=MessageRole.ASSISTANT)\n\u001b[32m    584\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\Desktop\\Ai-researcher\\.venv\\Lib\\site-packages\\llama_index\\core\\agent\\react\\step.py:437\u001b[39m, in \u001b[36mReActAgentWorker._get_response\u001b[39m\u001b[34m(self, current_reasoning, sources)\u001b[39m\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo reasoning steps were taken.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(current_reasoning) == \u001b[38;5;28mself\u001b[39m._max_iterations:\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mReached max iterations.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(current_reasoning[-\u001b[32m1\u001b[39m], ResponseReasoningStep):\n\u001b[32m    440\u001b[39m     response_step = cast(ResponseReasoningStep, current_reasoning[-\u001b[32m1\u001b[39m])\n",
      "\u001b[31mValueError\u001b[39m: Reached max iterations."
     ]
    }
   ],
   "source": [
    "answer = agent.chat(\"Downlod all the papers you just metioned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df2f0504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. Title: How do Large Language Models Understand Relevance? A Mechanistic Interpretability Perspective\n",
       "   Summary: This paper explores how different modules of Large Language Models (LLMs) contribute to relevance judgment through mechanistic interpretability.\n",
       "   Authors: Qi Liu, Jiaxin Mao, Ji-Rong Wen\n",
       "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07898v1)\n",
       "\n",
       "2. Title: Porting an LLM based Application from ChatGPT to an On-Premise Environment\n",
       "   Summary: The paper discusses the process of porting a real-life application using ChatGPT from a public cloud to an on-premise environment.\n",
       "   Authors: Teemu Paloniemi, Manu Setälä, Tommi Mikkonen\n",
       "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07907v1)\n",
       "\n",
       "3. Title: Redefining Machine Translation on Social Network Services with Large Language Models\n",
       "   Summary: This paper introduces RedTrans, a Large Language Model tailored for Social Network Services translation, outperforming state-of-the-art models.\n",
       "   Authors: Hongcheng Guo, Fei Zhao, Shaosheng Cao, Xinze Lyu, Ziyan Liu, Yue Wang, Boyang Wang, Zhoujun Li, Chonggang Lu, Zhe Xu, Yao Hu\n",
       "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07901v1)\n",
       "\n",
       "4. Title: Cat, Rat, Meow: On the Alignment of Language Model and Human Term-Similarity Judgments\n",
       "   Summary: The paper evaluates language models for their alignment with human similarity judgments on a word triplet task.\n",
       "   Authors: Lorenz Linhardt, Tom Neuhäuser, Lenka Tětková, Oliver Eberle\n",
       "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07965v1)\n",
       "\n",
       "5. Title: GLUS: Global-Local Reasoning Unified into A Single Large Language Model for Video Segmentation\n",
       "   Summary: This paper proposes a framework using multi-modal large language models for video object segmentation, achieving state-of-the-art results.\n",
       "   Authors: Lang Lin, Xueyang Yu, Ziqi Pang, Yu-Xiong Wang\n",
       "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07962v1)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(answer.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e3cc324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 3b94512d-5107-4266-b05e-683ae996eb2a. Step input: I am intersted in Quntum Computing.\n",
      "Find papers in your knowledge base that discuss this topic.\n",
      "Use the folling template to query research_paper_query_engine_tool tool: \n",
      "'Provide title, summary, author and link to download the PDF for papers related to Quntum Computing'\n",
      "If there are no papers, could you fetch the recent ones from arXiv?\n",
      "\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: reesarch_paper_query_engine_tool\n",
      "Action Input: {'input': 'Provide title, summary, author and link to download the PDF for papers related to Quantum Computing'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Title: None\n",
      "Summary: None\n",
      "Authors: None\n",
      "PDF URL: None\n",
      "\u001b[0m> Running step 80a8a651-93ce-45af-9eac-05f9b5abe4f1. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The tool did not provide any papers related to Quantum Computing in the knowledge base.\n",
      "Action: fetch_from_arxiv\n",
      "Action Input: {'title': 'Quantum Computing', 'paper_count': 5}\n",
      "\u001b[0m\u001b[1;3;34mObservation: [{'title': 'Quantum Speed Limit in Driven-dissipative Systems', 'summary': 'Every quantum operation that takes a system from one state to another is\\nknown to have bounds on operation time, due to Heisenberg uncertainty\\nprinciple. In open quantum systems (OQS), such bounds have been principally\\naffected by system environment coupling. In the recent past, drives on OQS have\\nshown to give rise to drive-induced dissipation (DID). In this work, we\\ninvestigate how DID affects the quantum speed limits. To this end, we use a\\nrecently-reported quantum master equation that takes into account environment\\nfluctuations and provide a closed form estimate of drive-induced dissipation.\\nOn such a system, we use Gradient Ascent Pulse Engineering (GRAPE) to find\\noptimal route to move from an initial state to a desired final state. Our key\\nresult is that there exists an optimal evolution time that maximizes fidelity.\\nThis work enables robust quantum control in open systems, addressing a key\\nchallenge in scaling quantum technologies. By improving fidelity and\\nefficiency, our method advances practical quantum computing under realistic\\ndissipative conditions.', 'published': datetime.datetime(2025, 4, 10, 17, 46, 43, tzinfo=datetime.timezone.utc), 'journal_ref': None, 'doi': None, 'primary_category': 'quant-ph', 'categories': ['quant-ph'], 'pdf_url': 'http://arxiv.org/pdf/2504.07931v1', 'arxiv_url': 'http://arxiv.org/abs/2504.07931v1', 'authors': ['Sarfraj Fency', 'Riddhi Chatterjee', 'Rangeet Bhattacharyya']}, {'title': 'Temporal Tensors and Quantum Shortcut Dynamics in a Supermaze of Multidimensional Time', 'summary': \"We develop a theoretical framework that unifies concepts of multiple time\\ndimensions, quantum shortcut dynamics, and complex topological structures\\n('supermazes') to explore novel phenomena in quantum and classical systems. In\\nparticular, we introduce a Temporal Tensor Formalism to describe\\nmultidimensional time, define Quantum Shortcut Operators that enact\\nnear-instantaneous state transitions, and incorporate these into a supermaze\\ntopological model inspired by labyrinthine geometry and network complexity. We\\nshow how this framework can give rise to surprising effects such as anomalous\\nthermodynamic relaxation (analogous to the Mpemba effect) in quantum systems.\\nTheoretical implications for quantum computing (including quantum cloud\\nnetworks) are discussed, and connections are drawn to established mathematical\\nparadoxes and physical principles.\", 'published': datetime.datetime(2025, 4, 10, 16, 19, 56, tzinfo=datetime.timezone.utc), 'journal_ref': None, 'doi': None, 'primary_category': 'quant-ph', 'categories': ['quant-ph', 'cs.ET', '14J60 (Primary) 14F05, 14J26 (Secondary)', 'F.2.2; I.2.7; I.2.8'], 'pdf_url': 'http://arxiv.org/pdf/2504.07900v1', 'arxiv_url': 'http://arxiv.org/abs/2504.07900v1', 'authors': ['Koffka Khan']}, {'title': 'QubitHammer Attacks: Qubit Flipping Attacks in Multi-tenant Superconducting Quantum Computers', 'summary': 'Quantum computing is rapidly evolving its capabilities, with a corresponding\\nsurge in its deployment within cloud-based environments. Various quantum\\ncomputers are accessible today via pay-as-you-go cloud computing models,\\noffering unprecedented convenience. Due to its rapidly growing demand, quantum\\ncomputers are shifting from a single-tenant to a multi-tenant model to enhance\\nresource utilization. However, this widespread accessibility to shared\\nmulti-tenant systems also introduces potential security vulnerabilities. In\\nthis work, we present for the first time a set of novel attacks, named together\\nas the QubitHammer attacks, which target state-of-the-art superconducting\\nquantum computers. We show that in a multi-tenant cloud-based quantum system,\\nan adversary with the basic capability to deploy custom pulses, similar to any\\nstandard user today, can utilize the QubitHammer attacks to significantly\\ndegrade the fidelity of victim circuits located on the same quantum computer.\\nUpon extensive evaluation, the QubitHammer attacks achieve a very high\\nvariational distance of up to 0.938 from the expected outcome, thus\\ndemonstrating their potential to degrade victim computation. Our findings\\nexhibit the effectiveness of these attacks across various superconducting\\nquantum computers from a leading vendor, suggesting that QubitHammer represents\\na new class of security attacks. Further, the attacks are demonstrated to\\nbypass all existing defenses proposed so far for ensuring the reliability in\\nmulti-tenant superconducting quantum computers.', 'published': datetime.datetime(2025, 4, 10, 15, 50, 57, tzinfo=datetime.timezone.utc), 'journal_ref': None, 'doi': None, 'primary_category': 'quant-ph', 'categories': ['quant-ph', 'cs.CR'], 'pdf_url': 'http://arxiv.org/pdf/2504.07875v1', 'arxiv_url': 'http://arxiv.org/abs/2504.07875v1', 'authors': ['Yizhuo Tan', 'Navnil Choudhury', 'Kanad Basu', 'Jakub Szefer']}, {'title': 'A quantum computing approach to beam angle optimization', 'summary': \"Background: Beam angle optimization (BAO) is a critical component of\\nradiation therapy (RT) treatment planning, where small changes in beam\\nconfiguration can significantly impact treatment quality, especially for proton\\nRT. Mathematically, BAO is a mixed integer programming (MIP) problem, which is\\nNP-hard due to its exponential growing search space. Traditional optimization\\ntechniques often struggle with computational efficiency, necessitating the\\ndevelopment of novel approaches. Purpose: This study introduces QC-BAO, a\\nhybrid quantum-classical approach that leverages quantum computing to solve the\\nMIP formulation of BAO. Methods: The proposed approach, QC-BAO, models BAO as\\nan MIP problem, incorporating binary variables for beam angle selection and\\ncontinuous variables for optimizing spot intensities for proton therapy. The\\nproposed approach employs a hybrid quantum-classical framework, utilizing\\nquantum computing to solve the binary decision component while integrating\\nclassical optimization techniques, including iterative convex relaxation and\\nalternating direction method of multipliers. Results: Computational experiments\\nwere conducted on clinical test cases to evaluate QC-BAO's performance against\\nclinically verified angles and a heuristic approach, GS-BAO. QC-BAO\\ndemonstrated improved treatment plan quality over both clinical and GS-BAO. The\\nmethod consistently increased the conformity index (CI) for target coverage\\nwhile reducing mean and maximum doses to organs-at-risk (OAR). Additionally,\\nQC-BAO produced the lowest objective function value, confirming its superior\\noptimization capability. Conclusions: The findings highlight the potential of\\nquantum computing to enhance the solution to BAO problem by demonstrated\\nimprovement in plan quality using the proposed method, QC-BAO. This study paves\\nthe way for future clinical implementation of quantum-accelerated optimization\\nin RT.\", 'published': datetime.datetime(2025, 4, 10, 15, 24, 37, tzinfo=datetime.timezone.utc), 'journal_ref': None, 'doi': None, 'primary_category': 'physics.med-ph', 'categories': ['physics.med-ph'], 'pdf_url': 'http://arxiv.org/pdf/2504.07844v1', 'arxiv_url': 'http://arxiv.org/abs/2504.07844v1', 'authors': ['Nimita Shinde', 'Ya-Nan Zhu', 'Haozheng Shen', 'Hao Gao']}, {'title': 'Efficient Formal Verification of Quantum Error Correcting Programs', 'summary': 'Quantum error correction (QEC) is fundamental for suppressing noise in\\nquantum hardware and enabling fault-tolerant quantum computation. In this\\npaper, we propose an efficient verification framework for QEC programs. We\\ndefine an assertion logic and a program logic specifically crafted for QEC\\nprograms and establish a sound proof system. We then develop an efficient\\nmethod for handling verification conditions (VCs) of QEC programs: for Pauli\\nerrors, the VCs are reduced to classical assertions that can be solved by SMT\\nsolvers, and for non-Pauli errors, we provide a heuristic algorithm. We\\nformalize the proposed program logic in Coq proof assistant, making it a\\nverified QEC verifier. Additionally, we implement an automated QEC verifier,\\nVeri-QEC, for verifying various fault-tolerant scenarios. We demonstrate the\\nefficiency and broad functionality of the framework by performing different\\nverification tasks across various scenarios. Finally, we present a benchmark of\\n14 verified stabilizer codes.', 'published': datetime.datetime(2025, 4, 10, 13, 28, 49, tzinfo=datetime.timezone.utc), 'journal_ref': None, 'doi': '10.1145/3729293', 'primary_category': 'cs.PL', 'categories': ['cs.PL', 'quant-ph'], 'pdf_url': 'http://arxiv.org/pdf/2504.07732v1', 'arxiv_url': 'http://arxiv.org/abs/2504.07732v1', 'authors': ['Qifan Huang', 'Li Zhou', 'Wang Fang', 'Mengyu Zhao', 'Mingsheng Ying']}]\n",
      "\u001b[0m> Running step b2909ee2-0300-4d7f-923e-27a2a3fb0914. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: (Implicit) I can answer without any more tools!\n",
      "Answer: 1. Title: Quantum Speed Limit in Driven-dissipative Systems\n",
      "   Summary: This work investigates how drive-induced dissipation affects quantum speed limits in open quantum systems, enabling robust quantum control under realistic dissipative conditions.\n",
      "   Authors: Sarfraj Fency, Riddhi Chatterjee, Rangeet Bhattacharyya\n",
      "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07931v1)\n",
      "\n",
      "2. Title: Temporal Tensors and Quantum Shortcut Dynamics in a Supermaze of Multidimensional Time\n",
      "   Summary: A theoretical framework is developed to explore novel phenomena in quantum and classical systems using multiple time dimensions, quantum shortcut dynamics, and complex topological structures.\n",
      "   Authors: Koffka Khan\n",
      "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07900v1)\n",
      "\n",
      "3. Title: QubitHammer Attacks: Qubit Flipping Attacks in Multi-tenant Superconducting Quantum Computers\n",
      "   Summary: This work introduces QubitHammer attacks targeting superconducting quantum computers in multi-tenant cloud environments, demonstrating potential security vulnerabilities.\n",
      "   Authors: Yizhuo Tan, Navnil Choudhury, Kanad Basu, Jakub Szefer\n",
      "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07875v1)\n",
      "\n",
      "4. Title: A quantum computing approach to beam angle optimization\n",
      "   Summary: QC-BAO, a hybrid quantum-classical approach, is proposed for beam angle optimization in radiation therapy treatment planning, showcasing improved treatment plan quality.\n",
      "   Authors: Nimita Shinde, Ya-Nan Zhu, Haozheng Shen, Hao Gao\n",
      "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07844v1)\n",
      "\n",
      "5. Title: Efficient Formal Verification of Quantum Error Correcting Programs\n",
      "   Summary: An efficient verification framework for quantum error correction programs is presented, including a sound proof system and an automated verifier, Veri-QEC.\n",
      "   Authors: Qifan Huang, Li Zhou, Wang Fang, Mengyu Zhao, Mingsheng Ying\n",
      "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07732v1)\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "answer = agent.chat(query_template.format(topic=\"Quntum Computing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf5ad8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. Title: Quantum Speed Limit in Driven-dissipative Systems\n",
       "   Summary: This work investigates how drive-induced dissipation affects quantum speed limits in open quantum systems, enabling robust quantum control under realistic dissipative conditions.\n",
       "   Authors: Sarfraj Fency, Riddhi Chatterjee, Rangeet Bhattacharyya\n",
       "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07931v1)\n",
       "\n",
       "2. Title: Temporal Tensors and Quantum Shortcut Dynamics in a Supermaze of Multidimensional Time\n",
       "   Summary: A theoretical framework is developed to explore novel phenomena in quantum and classical systems using multiple time dimensions, quantum shortcut dynamics, and complex topological structures.\n",
       "   Authors: Koffka Khan\n",
       "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07900v1)\n",
       "\n",
       "3. Title: QubitHammer Attacks: Qubit Flipping Attacks in Multi-tenant Superconducting Quantum Computers\n",
       "   Summary: This work introduces QubitHammer attacks targeting superconducting quantum computers in multi-tenant cloud environments, demonstrating potential security vulnerabilities.\n",
       "   Authors: Yizhuo Tan, Navnil Choudhury, Kanad Basu, Jakub Szefer\n",
       "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07875v1)\n",
       "\n",
       "4. Title: A quantum computing approach to beam angle optimization\n",
       "   Summary: QC-BAO, a hybrid quantum-classical approach, is proposed for beam angle optimization in radiation therapy treatment planning, showcasing improved treatment plan quality.\n",
       "   Authors: Nimita Shinde, Ya-Nan Zhu, Haozheng Shen, Hao Gao\n",
       "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07844v1)\n",
       "\n",
       "5. Title: Efficient Formal Verification of Quantum Error Correcting Programs\n",
       "   Summary: An efficient verification framework for quantum error correction programs is presented, including a sound proof system and an automated verifier, Veri-QEC.\n",
       "   Authors: Qifan Huang, Li Zhou, Wang Fang, Mengyu Zhao, Mingsheng Ying\n",
       "   PDF URL: [Download PDF](http://arxiv.org/pdf/2504.07732v1)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(answer.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e99c04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
